---
title: "Dog-SEP"
subtitle: "Machine learning: random forests"
pagetitle: "Dog-SEP: RF"
author: "Radoslaw Panczak"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document: 
    highlight: pygments
    keep_md: no
    number_sections: yes
    theme: united
    toc: yes
    toc_depth: 4
    self_contained: true
    toc_float: yes
editor_options: 
  chunk_output_type: console
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../docs") })
---

<!-- ------------------------------------------------------------ --> 

```{r r-setup, include=FALSE}
set.seed(12345)
options(scipen = 999)
options(max.print = "75")

library(pacman)
p_load(tidyverse, magrittr, DT,
       caret, randomForest, ranger)

import::from("sjmisc", "frq")
```

```{r knit-setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                      fig.width = 8, fig.height = 6, dpi = 300, 
                      out.width = "800px", out.height = "600px")

knitr::opts_chunk$set(cache = FALSE,
                      prompt = FALSE,
                      tidy = FALSE,
                      comment = NA,
                      message = FALSE,
                      warning = FALSE)

knitr::opts_knit$set(width = 75)

mu <- Hmisc::markupSpecs$html
```

```{r include=FALSE}
MAE <- function(actual, predicted) {
  mean(abs(actual - predicted))  
}
```

<!-- ------------------------------------------------------------ --> 

# Background 

Using info from chapter 7 of *Machine Learning with R* [book](https://www.packtpub.com/product/machine-learning-with-r-third-edition/9781788295864), `caret` package [manual](https://topepo.github.io/caret/index.html), and `randomForest` [package](https://cran.r-project.org/web/packages/randomForest/index.html). 

<!-- ------------------------------------------------------------ --> 

# Analysis with `randomForest`

## Data 

```{r include=FALSE}
training <- read_rds("data/training.Rds")
testing <- read_rds("data/testing.Rds")
```

## Training 

```{r}
set.seed(12345)
m_rf <- randomForest(outcome ~ ., data = training)
```

```{r echo=FALSE}
summary(m_rf)
```

```{r echo=FALSE}
plot(m_rf)
```

```{r echo=FALSE}
varImpPlot(m_rf, main = "Feature importance")
```

## Prediction

```{r}
p_rf <- predict(m_rf, testing[-1])
```

Correlation:  

```{r}
cor(p_rf, testing$outcome)
```

MAE between predicted and actual values:  

```{r}
MAE(p_rf, testing$outcome)
```

Distro of predicted (red) nd actual (green): 

```{r echo=FALSE}
# summary(p_rf)
# summary(testing$outcome)

ggplot() +
  geom_density(data = as.data.frame(p_rf), aes(x = p_rf), col = "firebrick") +
  geom_density(data = testing, aes(x = outcome), col = "forestgreen") 
```

## Tuning

```{r}
modelLookup("rf")
```

Using grid of parameters to explore:  

```{r}
grid_tu <- expand.grid(mtry = seq(5, ncol(training) - 1, 1))

nrow(grid_tu)
```

```{r}
p_load(doParallel)

cl <- makePSOCKcluster(parallel::detectCores())
registerDoParallel(cl)

set.seed(12345)
m_rf_tu <- train(outcome ~ .,
                 method = "rf",
                 data = training,
                 # weights = training_weights, 
                 metric = "RMSE",
                 # metric = "Rsquared",
                 tuneGrid = grid_tu)

stopCluster(cl)
p_unload(doParallel)
```

```{r include=FALSE}
write_rds(m_rf_tu, "results/m_rf_tu.Rds")
```

```{r echo=FALSE}
# summary(m_rf_tu)
ggplot(m_rf_tu)
```

```{r}
m_rf_tu$finalModel
```

```{r echo=FALSE}
varImpPlot(m_rf_tu$finalModel, main = "Feature importance")
```

```{r}
p_rf_tu <- predict(m_rf_tu, testing[-1])
```

Correlation:  

```{r}
cor(p_rf_tu, testing$outcome)
```

MAE between predicted and actual values:  

```{r}
MAE(p_rf_tu, testing$outcome)
```

Distro of predicted (red) nd actual (green): 

```{r echo=FALSE}
# summary(p_rf)
# summary(testing$outcome)

ggplot() +
  geom_density(data = as.data.frame(p_rf_tu), aes(x = p_rf_tu), col = "firebrick") +
  geom_density(data = testing, aes(x = outcome), col = "forestgreen") 
```

<!-- ------------------------------------------------------------ --> 

# Analysis with `ranger`

## Training 

```{r}
set.seed(12345)
m_rf2 <- ranger(outcome ~ ., data = training, 
                importance = "impurity") # impurity, impurity_corrected, permutation
```

```{r echo=FALSE}
summary(m_rf2)
```

```{r echo=FALSE}
importance(m_rf2) %>% 
  as_tibble(rownames = "breed") %>% 
  arrange(desc(value)) %>% 
  slice(1:20) %>% 
  mutate(breed = fct_reorder(breed, value)) %>%
  ggplot() +
  geom_col(aes(x = breed, y = value)) +
  coord_flip()
```

## Prediction

```{r}
p_rf2 <- predict(m_rf2, testing[-1])
```

Correlation:  

```{r}
cor(p_rf2$predictions, testing$outcome)
```

MAE between predicted and actual values:  

```{r}
MAE(p_rf2$predictions, testing$outcome)
```

Distro of predicted (red) nd actual (green): 

```{r echo=FALSE}
# summary(p_rf)
# summary(testing$outcome)

ggplot() +
  geom_density(data = as.data.frame(p_rf2$predictions), aes(x = p_rf2$predictions), col = "firebrick") +
  geom_density(data = testing, aes(x = outcome), col = "forestgreen") 
```

## Tuning

```{r}
modelLookup("ranger")
```

Using grid of parameters to explore:  

```{r}
grid_tu <- expand.grid(mtry = seq(5, ncol(training) - 1, 1),
                       splitrule = c("variance", "extratrees", "maxstat", "beta"),
                       min.node.size = seq(3, 30, 1))

nrow(grid_tu)
```

```{r}
p_load(doParallel)

cl <- makePSOCKcluster(parallel::detectCores())
registerDoParallel(cl)

set.seed(12345)
m_rf2_tu <- train(outcome ~ .,
                  method = "ranger",
                  data = training,
                  # weights = training_weights, 
                  metric = "RMSE",
                  # metric = "Rsquared",
                  tuneGrid = grid_tu)

stopCluster(cl)
p_unload(doParallel)
```

```{r include=FALSE}
write_rds(m_rf2_tu, "results/m_rf2_tu.Rds")
```

```{r echo=FALSE}
# summary(m_rf_tu)
ggplot(m_rf2_tu)
```

```{r}
m_rf2_tu$finalModel
```

```{r}
p_rf2_tu <- predict(m_rf2_tu, testing[-1])
```

Correlation:  

```{r}
cor(p_rf2_tu, testing$outcome)
```

MAE between predicted and actual values:  

```{r}
MAE(p_rf2_tu, testing$outcome)
```

Distro of predicted (red) nd actual (green): 

```{r echo=FALSE}
# summary(p_rf)
# summary(testing$outcome)

ggplot() +
  geom_density(data = as.data.frame(p_rf2_tu), aes(x = p_rf2_tu), col = "firebrick") +
  geom_density(data = testing, aes(x = outcome), col = "forestgreen") 
```