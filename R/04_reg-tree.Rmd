---
title: "Dog-SEP"
subtitle: "Machine learning: regression trees"
pagetitle: "Dog-SEP: reg tree"
author: "Radoslaw Panczak"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document: 
    highlight: pygments
    keep_md: no
    number_sections: yes
    theme: united
    toc: yes
    toc_depth: 4
    self_contained: true
    toc_float: yes
editor_options: 
  chunk_output_type: console
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../docs") })
---

<!-- ------------------------------------------------------------ --> 

```{r r-setup, include=FALSE}
set.seed(12345)
options(scipen = 999)
options(max.print = "75")

library(pacman)
p_load(tidyverse, magrittr, DT,
       caret, rpart, rpart.plot, Cubist)

import::from("sjmisc", "frq")
```

```{r knit-setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                      fig.width=8, fig.height=6, dpi=300, 
                      out.width="800px", out.height="600px")

knitr::opts_chunk$set(cache = FALSE,
                      prompt = FALSE,
                      tidy = FALSE,
                      comment = NA,
                      message = FALSE,
                      warning = FALSE)

knitr::opts_knit$set(width = 75)

mu <- Hmisc::markupSpecs$html
```

```{r include=FALSE}
# function to calculate the mean absolute error
MAE <- function(actual, predicted) {
  mean(abs(actual - predicted))  
}
```

<!-- ------------------------------------------------------------ --> 

# Data 

## Prepared data

Preparations in file `00.Rmd`.  

Using `IEO` as outcome.  

```{r}
# wide_all_n <- read_rds("data/wide_all_n.Rds")

wide_all_p <- read_rds("data/wide_all_p.Rds") %>% 
  sf::st_drop_geometry() %>% 
  # as_tibble() %>% 
  select(IEO, IEO_d, 
         akita:swedish_lapphund) %>% 
  rename(outcome = IEO,
         outcome_d = IEO_d)

# skimr::skim(wide_all_p)
# report::report(wide_all_p)
```

## Train split

75/25 split, taking into account distribution of deciles:    

```{r}
inTrain <- createDataPartition(
  y = wide_all_p$outcome_d,
  p = .75,
  list = FALSE
)

training <- wide_all_p[ inTrain,]
testing  <- wide_all_p[-inTrain,]
```

Training data:  

```{r echo=FALSE}
# nrow(training)
frq(training, outcome_d)
```

Testing data:  

```{r echo=FALSE}
# nrow(testing)
frq(testing, outcome_d)
```

```{r include=FALSE}
training <- select(training, -outcome_d)
testing <- select(testing, -outcome_d)
```

Outcome distro checks  

```{r echo=FALSE}
ggplot() +
  geom_density(data = training, aes(x = outcome), col = "forestgreen") +
  geom_density(data = testing, aes(x = outcome), col = "firebrick") 
```

## Checks

### Near zero-variance 

```{r}
nzv <- nearZeroVar(wide_all_p, saveMetrics = TRUE)
```

```{r echo=FALSE}
nzv %>% 
  filter(nzv == TRUE) %>% 
  datatable()
```

```{r}
nzv <- nearZeroVar(wide_all_p)
wide_all_p <- wide_all_p[, -nzv]
```

### Correlated breeds

```{r}
descr_cor <- cor(wide_all_p %>% select(-outcome, -outcome_d)) %>% 
  as_tibble(rownames = "rowname") %>% 
  pivot_longer(-rowname) %>% 
  filter(rowname != name) %>% 
  arrange(desc(value)) %>% 
  filter(row_number() %% 2 == 1) %>% 
  mutate(value = scales::number(value, accuracy = 0.01)) %>% 
  rename(correlation = value)
```

```{r echo=FALSE}
descr_cor %>% 
  datatable()
```

### Linear combinations

```{r}
combo_info <- findLinearCombos(wide_all_p %>% select(-outcome, -outcome_d))
combo_info
```


<!-- ------------------------------------------------------------ --> 

# Analysis with `rpart`

## Training 

```{r}
set.seed(12345)
m_rpart <- rpart(outcome ~ ., data = training)
```

```{r echo=FALSE}
m_rpart
# summary(m_rpart)
```

```{r echo=FALSE}
rpart.plot(m_rpart, digits = 3)
```

```{r echo=FALSE}
rpart.plot(m_rpart, digits = 3, fallen.leaves = TRUE, type = 3, extra = 101)
```

```{r eval=FALSE, include=FALSE}
rattle::fancyRpartPlot(m_rpart)
```

## Prediction

```{r}
p_rpart <- predict(m_rpart, testing)
```

Correlation:  

```{r}
cor(p_rpart, testing$outcome)
```

MAE between predicted and actual values:  

```{r}
MAE(p_rpart, testing$outcome)
```

```{r eval=FALSE, include=FALSE}
# mean absolute error between actual values and mean value
# mean(training$outcome) 
MAE(mean(training$outcome), testing$outcome)
```

Distro of predicted (red) nd actual (green): 

```{r echo=FALSE}
# summary(p_rpart)
# summary(testing$outcome)

ggplot() +
  geom_density(data = as.data.frame(p_rpart), aes(x = p_rpart), col = "firebrick") +
  geom_density(data = testing, aes(x = outcome), col = "forestgreen") 
```

## Tuning

```{r}
modelLookup("rpart")
```

```{r}
p_load(doParallel)

cl <- makePSOCKcluster(parallel::detectCores())
registerDoParallel(cl)

set.seed(12345)
m_rpart_tu <- train(outcome ~ .,
                    method = "rpart",
                    # method = "rpart2", # uses max tree depth
                    data = training,
                    metric = "RMSE",
                    # metric = "Rsquared",
                    tuneLength = 50)

stopCluster(cl)
p_unload(doParallel)
```

```{r echo=FALSE}
# summary(m_rpart_tu)
ggplot(m_rpart_tu)
```

```{r}
m_rpart_tu$finalModel
```

```{r}
p_rpart_tu <- predict(m_rpart_tu, testing)
```

Correlation:  

```{r}
cor(p_rpart_tu, testing$outcome)
```

MAE between predicted and actual values:  

```{r}
MAE(p_rpart_tu, testing$outcome)
```

Distro of predicted (red) nd actual (green): 

```{r echo=FALSE}
# summary(p_rpart)
# summary(testing$outcome)

ggplot() +
  geom_density(data = as.data.frame(p_rpart_tu), aes(x = p_rpart_tu), col = "firebrick") +
  geom_density(data = testing, aes(x = outcome), col = "forestgreen") 
```

# Analysis with `Cubist`

## Training   

```{r}
set.seed(12345)
m_cubist <- cubist(x = training[-1], y = training$outcome)
```

```{r echo=FALSE}
# m_cubist
summary(m_cubist)
```

## Prediction

```{r}
# generate predictions for the model
p_cubist <- predict(m_cubist, testing)
```

Correlation:  

```{r}
cor(p_cubist, testing$outcome)
```

MAE between predicted and actual values:  

```{r}
MAE(testing$outcome, p_cubist)
```

Distro of predicted (red) nd actual (green): 

```{r echo=FALSE}
ggplot() +
  geom_density(data = as.data.frame(p_cubist), aes(x = p_cubist), col = "firebrick") +
  geom_density(data = testing, aes(x = outcome), col = "forestgreen") 
```